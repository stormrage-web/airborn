{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Предобработка / чтение"
      ],
      "metadata": {
        "id": "yMG3QEzd7ow6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcYV-6wm7mDz"
      },
      "outputs": [],
      "source": [
        "pip install etna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ruptures"
      ],
      "metadata": {
        "id": "6bz7x6_D_CT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import date\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "import prophet\n",
        "import holidays\n",
        "# импортируем необходимую функцию \n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "#добавим нужную библиотеку\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from scipy.signal import find_peaks\n",
        "from statsmodels.graphics import tsaplots"
      ],
      "metadata": {
        "id": "tW4GD6M67y9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-dVmvZuQ79zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in os.listdir('/content/drive/MyDrive/Датасеты/'):\n",
        "    !unrar e /content/drive/MyDrive/Датасеты/{i}"
      ],
      "metadata": {
        "id": "HTlahq6I7_vY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Определение динамики бронирований рейса в разрезе классов бронирования по вылетевшим рейсам. (2017-2019 год)"
      ],
      "metadata": {
        "id": "0vGqz7ku8D4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# получение данных из файла по бронированию \n",
        "def get_data(path,flt_num,class_code,dd):\n",
        "  class_df = pd.read_csv(path, delimiter=';')\n",
        "  class_df = class_df.loc[(class_df['FLT_NUM']==flt_num) &\n",
        "                          (class_df['SEG_CLASS_CODE']==class_code) & (class_df[\"DD\"]==dd) & (class_df.DTD!=-1)]\n",
        "  class_df.DD = class_df.DD.apply(lambda x: datetime.strptime(x, '%d.%m.%Y').date())\n",
        "  class_df.SDAT_S = class_df.SDAT_S.apply(lambda x: datetime.strptime(x, '%d.%m.%Y').date())\n",
        "  return class_df"
      ],
      "metadata": {
        "id": "P55tTNQX8ATG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# получение динамики бронирования по конкретному рейсу и классу на определенную дату\n",
        "def get_booking(df):\n",
        "\n",
        "  if len(df)==0:\n",
        "    print(\"Бронирований по данному рейсу нет\")\n",
        "    return None\n",
        "\n",
        "  df = df.sort_values(by=[\"SDAT_S\"])\n",
        "  df = df[[\"SDAT_S\",\"PASS_BK\"]]\n",
        "  df = df.sort_values(by=[\"SDAT_S\"])\n",
        "\n",
        "  start_date = df.SDAT_S.min()\n",
        "  end_date = df.SDAT_S.max()\n",
        "\n",
        "  res = pd.date_range(\n",
        "      min(start_date, end_date),\n",
        "      max(start_date, end_date)\n",
        "  ).strftime('%Y-%m-%d')\n",
        "  df[\"SDAT_S\"] = df[\"SDAT_S\"].astype(\"datetime64\")\n",
        "  df_data = pd.DataFrame(columns=[\"SDAT_S\"],data=res)\n",
        "  df_data[\"SDAT_S\"] = df_data.SDAT_S.astype(\"datetime64\")\n",
        "  df = df_data.merge(df,on=\"SDAT_S\",how=\"left\").fillna(method=\"bfill\").replace(np.nan,0)\n",
        "\n",
        "  df[\"SDAT_S\"] = df[\"SDAT_S\"].apply(lambda x: datetime.date(x))\n",
        "\n",
        "  if df[\"PASS_BK\"].sum()==0:\n",
        "    print(\"Бронирований за указанный период нет\")\n",
        "    return None\n",
        "  \n",
        "\n",
        "  # df.groupby('SDAT_S').sum().plot(kind='bar', figsize=(13,8), linewidth=1.0)\n",
        "\n",
        "  \n",
        "  return df[['SDAT_S', 'PASS_BK']]"
      ],
      "metadata": {
        "id": "vD5rbqQW8J4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# получение роста динамики бронирования и нормализация этих значений\n",
        "def get_booking_dynamics(data):\n",
        "\n",
        "  # в относительных значениях \n",
        "   \n",
        "  # будет с заполнением пропусков \n",
        "  df = get_booking(data.sort_values(by=[\"SDAT_S\"]))\n",
        "  if df is None:\n",
        "    return None\n",
        "\n",
        "  df = df.reset_index(drop=True)\n",
        "  df[\"delta_book\"] = df[\"PASS_BK\"].shift(1,fill_value = df[\"PASS_BK\"][0])\n",
        "  df[\"delta\"] = [max(0,(x-y))   for x,y in zip(df[\"PASS_BK\"],df[\"delta_book\"])]\n",
        "  df[\"delta\"][0]  = df[\"delta_book\"][0]\n",
        "  \n",
        "  df = df[[\"SDAT_S\",\"delta\"]]\n",
        "  df = df.sort_values(by=[\"SDAT_S\"])\n",
        "\n",
        "  start_date = df.SDAT_S.min()\n",
        "  end_date = df.SDAT_S.max()\n",
        "\n",
        "  res = pd.date_range(\n",
        "      min(start_date, end_date),\n",
        "      max(start_date, end_date)\n",
        "  ).strftime('%Y-%m-%d')\n",
        "  df[\"SDAT_S\"] = df[\"SDAT_S\"].astype(\"datetime64\")\n",
        "  df_data = pd.DataFrame(columns=[\"SDAT_S\"],data=res)\n",
        "  df_data[\"SDAT_S\"] = df_data.SDAT_S.astype(\"datetime64\")\n",
        "\n",
        "  df = df_data.merge(df,on=\"SDAT_S\",how=\"left\").replace(np.nan,0)\n",
        "\n",
        "  df[\"SDAT_S\"] = df[\"SDAT_S\"].apply(lambda x: datetime.date(x))\n",
        "\n",
        "  df=df[['SDAT_S', 'delta']]\n",
        "\n",
        "  if df[\"delta\"].sum()==0:\n",
        "    print(\"Динамики бронирований нет\")\n",
        "    return None\n",
        "  \n",
        "\n",
        "  df[\"delta_freq\"] = df[\"delta\"]/df[\"delta\"].sum()\n",
        "  # df[[\"SDAT_S\",\"delta_freq\"]].groupby('SDAT_S').sum().plot(kind='bar', figsize=(13,8), linewidth=1.0)\n",
        "\n",
        "\n",
        "  return df[['SDAT_S', 'delta_freq']]"
      ],
      "metadata": {
        "id": "XMNZVtPf8fGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# получение роста динамики бронирования\n",
        "def get_absolute_booking_dynamics(data):\n",
        "  # в абсолютных значениях для других графиков\n",
        "   \n",
        "  df = get_booking(data.sort_values(by=[\"SDAT_S\"]))\n",
        "\n",
        "  if len(df)==0:\n",
        "    print(\"Бронирований нет\")\n",
        "    return None\n",
        "\n",
        "  df = df.reset_index(drop=True)\n",
        "  df[\"delta_book\"] = df[\"PASS_BK\"].shift(1,fill_value = df[\"PASS_BK\"][0])\n",
        "  df[\"delta\"] = [max(0,(x-y))   for x,y in zip(df[\"PASS_BK\"],df[\"delta_book\"])]\n",
        "  df[\"delta\"][0]  = df[\"delta_book\"][0]\n",
        "  \n",
        "  df = df[[\"SDAT_S\",\"delta\"]]\n",
        "  df = df.sort_values(by=[\"SDAT_S\"])\n",
        "\n",
        "  start_date = df.SDAT_S.min()\n",
        "  end_date = df.SDAT_S.max()\n",
        "\n",
        "  res = pd.date_range(\n",
        "      min(start_date, end_date),\n",
        "      max(start_date, end_date)\n",
        "  ).strftime('%Y-%m-%d')\n",
        "  df[\"SDAT_S\"] = df[\"SDAT_S\"].astype(\"datetime64\")\n",
        "  df_data = pd.DataFrame(columns=[\"SDAT_S\"],data=res)\n",
        "  df_data[\"SDAT_S\"] = df_data.SDAT_S.astype(\"datetime64\")\n",
        "  df = df_data.merge(df,on=\"SDAT_S\",how=\"left\").replace(np.nan,0)\n",
        "\n",
        "  df[\"SDAT_S\"] = df[\"SDAT_S\"].apply(lambda x: datetime.date(x))\n",
        "\n",
        "  df=df[['SDAT_S', 'delta']]\n",
        "\n",
        "  if df[\"delta\"].sum()==0:\n",
        "    print(\"Динамики бронирований нет\")\n",
        "    return None\n",
        "  \n",
        "\n",
        "  # df[[\"SDAT_S\",\"delta_freq\"]].groupby('SDAT_S').sum().plot(kind='bar', figsize=(13,8), linewidth=1.0)\n",
        "\n",
        "\n",
        "  return df[['SDAT_S', 'delta']]"
      ],
      "metadata": {
        "id": "9m6sFVgI8rNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#example\n",
        "flight_num = 1125\n",
        "booking_class = 'J'\n",
        "dd = \"04.03.2019\"\n",
        "class_df = get_data('/content/CLASS_012018.csv', flight_num, booking_class,dd)\n",
        "class_df = class_df.append(get_data('/content/CLASS_022018.csv', flight_num, booking_class,dd))\n",
        "class_df = class_df.append(get_data('/content/CLASS_032018.csv', flight_num, booking_class,dd))\n",
        "class_df = class_df.append(get_data('/content/CLASS_042018.csv', flight_num, booking_class,dd))\n",
        "class_df = class_df.append(get_data('/content/CLASS_052018.csv', flight_num, booking_class,dd))\n",
        "class_df = class_df.append(get_data('/content/CLASS_062018.csv', flight_num, booking_class,dd))\n",
        "class_df = class_df.append(get_data('/content/CLASS_072018.csv', flight_num, booking_class,dd))\n",
        "class_df = class_df.append(get_data('/content/CLASS_082018.csv', flight_num, booking_class,dd))\n",
        "class_df = class_df.append(get_data('/content/CLASS_092018.csv', flight_num, booking_class,dd))\n",
        "class_df = class_df.append(get_data('/content/CLASS_102018.csv', flight_num, booking_class,dd))\n",
        "class_df = class_df.append(get_data('/content/CLASS_112018.csv', flight_num, booking_class,dd))\n",
        "class_df = class_df.append(get_data('/content/CLASS_122018.csv', flight_num, booking_class,dd))\n",
        "class_df = class_df.append(get_data('/content/CLASS_012019.csv', flight_num, booking_class,dd))\n",
        "class_df = class_df.append(get_data('/content/CLASS_022019.csv', flight_num, booking_class,dd))\n",
        "class_df = class_df.append(get_data('/content/CLASS_032019.csv', flight_num, booking_class,dd))\n",
        "class_df = class_df.append(get_data('/content/CLASS_042019.csv', flight_num, booking_class,dd))\n",
        "class_df = class_df.append(get_data('/content/CLASS_052019.csv', flight_num, booking_class,dd))\n",
        "class_df = class_df.append(get_data('/content/CLASS_062019.csv', flight_num, booking_class,dd))\n",
        "class_df = class_df.append(get_data('/content/CLASS_072019.csv', flight_num, booking_class,dd))\n",
        "class_df = class_df.append(get_data('/content/CLASS_082019.csv', flight_num, booking_class,dd))\n",
        "class_df = class_df.append(get_data('/content/CLASS_092019.csv', flight_num, booking_class,dd))\n",
        "class_df = class_df.append(get_data('/content/CLASS_102019.csv', flight_num, booking_class,dd))\n",
        "class_df = class_df.append(get_data('/content/CLASS_112019.csv', flight_num, booking_class,dd))\n",
        "class_df = class_df.append(get_data('/content/CLASS_122019.csv', flight_num, booking_class,dd))\n",
        "result = get_booking(class_df)"
      ],
      "metadata": {
        "id": "HSRqVicw8y6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Определение сезонности спроса по классам бронирования, по вылетевшим рейсам. (2017-2019 год)"
      ],
      "metadata": {
        "id": "bkEBnFAt-tk_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Сезонность сброса (без динамики бронирования)"
      ],
      "metadata": {
        "id": "o2FgDSqf_Kcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  получение даты для определения сезонности \n",
        "def get_data_to_season(path,flt_num,class_code):\n",
        "  class_df = pd.read_csv(path, delimiter=';')\n",
        "  class_df = class_df.loc[(class_df['FLT_NUM']==flt_num) &\n",
        "                          (class_df['SEG_CLASS_CODE']==class_code) & (class_df.DD==class_df.SDAT_S) ]\n",
        "  class_df.DD = class_df.DD.apply(lambda x: datetime.strptime(x, '%d.%m.%Y').date())\n",
        "  class_df.SDAT_S = class_df.SDAT_S.apply(lambda x: datetime.strptime(x, '%d.%m.%Y').date())\n",
        "  return class_df"
      ],
      "metadata": {
        "id": "AuAcWLrD-2h7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ruptures as rpt\n",
        "def check_season(df):\n",
        "  if df is None:\n",
        "    return None\n",
        "\n",
        "  start_date = df.DD.min()\n",
        "  end_date = df.DD.max()\n",
        "\n",
        "  res = pd.date_range(\n",
        "      min(start_date, end_date),\n",
        "      max(start_date, end_date)\n",
        "  ).strftime('%Y-%m-%d')\n",
        "\n",
        "  df_data = pd.DataFrame(columns=[\"DD\"],data=res)\n",
        "  df_data[\"DD\"] = df_data.DD.astype(\"datetime64\")\n",
        "\n",
        "  df = df[[\"DD\",\"PASS_BK\"]]\n",
        "    \n",
        "  df[\"DD\"] = df[\"DD\"].astype(\"datetime64\")\n",
        "  df= df_data.merge(df,on=\"DD\",how=\"left\").replace(np.nan,0)\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  df_to_save = df.copy()\n",
        "  df = df.set_index(\"DD\")\n",
        "  decomposition = seasonal_decompose(df['PASS_BK'],model=\"additive\")\n",
        "\n",
        "\n",
        "  df_to_save[\"month\"] = df_to_save[\"DD\"].apply(lambda x: x.month)\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "  df_to_save = df_to_save.reset_index(drop=True)\n",
        "  #сделать пока основные сезоны (летний, весенний,зимний и осенний)\n",
        "  df_to_save[\"season\"] = df_to_save.month.apply(lambda x: \"весна\" if (x>=3 and x<=5) else (\"лето\" if (x>=6 and x<=8) else (\"осень\" if (x>=9 and x<=11) else \"зима\")))\n",
        "\n",
        "  result = pd.DataFrame(columns=[\"PASS_BK\"], data = decomposition.trend.values)\n",
        "  result[\"PASS_BK\"] = result[\"PASS_BK\"].replace(np.nan,0)\n",
        "  result[\"DD\"] = decomposition.trend.index\n",
        " \n",
        "  result[\"season\"] = df_to_save[\"season\"]\n",
        "  \n",
        "\n",
        "  # off-line change point detection\n",
        "  model = \"l1\"  \n",
        "  algo = rpt.Dynp(model=model, min_size=15, jump=5).fit(df_to_save[\"PASS_BK\"].values)\n",
        "  my_bkps = algo.predict(n_bkps=10)\n",
        "  rpt.show.display(df_to_save[\"PASS_BK\"].values, my_bkps, figsize=(10, 6))\n",
        "  plt.title('Change Point Detection: Dynamic Programming Search Method')\n",
        "  plt.show()\n",
        "    \n",
        "  \n",
        "  # прикрутить этот индекс к данным\n",
        "\n",
        "\n",
        "\n",
        "  for i in range(1,len(my_bkps)-1):\n",
        "    if my_bkps[i]!=0:\n",
        "      if result.loc[my_bkps[i]:my_bkps[i+1]].PASS_BK.mean() > result.loc[my_bkps[i-1]:my_bkps[i]].PASS_BK.mean():\n",
        "        # если среднее по этому промежутку больше, чем в прошлом, то он повышенный\n",
        "        if \"пониженный\" not in result.loc[result.index == my_bkps[i-1], \"season\"].values[0]:\n",
        "          season = result.loc[result.index == my_bkps[i], \"season\"].values[0]\n",
        "          result.loc[my_bkps[i]][\"season\"] = \"повышенный \" + season\n",
        "          j=my_bkps[i]+1\n",
        "          while j<len(result) and j<= my_bkps[i+1]:\n",
        "              season = result.loc[result.index == j, \"season\"].values[0]\n",
        "              result.loc[result.index == j, \"season\"] = \"повышенный \" + season \n",
        "              j+=1\n",
        "\n",
        "      else:\n",
        "        # пониженный или обычный\n",
        "        if \"повышенный\" not in result.loc[result.index == my_bkps[i-1], \"season\"].values[0]:\n",
        "          # делаем пониженный\n",
        "          season = result.loc[result.index == my_bkps[i], \"season\"].values[0]\n",
        "          result.loc[my_bkps[i]][\"season\"] = \"пониженный \" + season\n",
        "          j=my_bkps[i]+1\n",
        "          while  j<len(result) and j<= my_bkps[i+1]:\n",
        "              season = result.loc[result.index == j, \"season\"].values[0]\n",
        "              result.loc[result.index == j, \"season\"] = \"пониженный \" + season \n",
        "              j+=1\n",
        "\n",
        "  # добавить праздники\n",
        "  for pass_bk,data,season in result.values:\n",
        "    if data.date() in holidays.Russia(years=[2017,2018,2019]).keys():\n",
        "          if  holidays.Russia(years=[2017,2018,2019])[data.date()]== \"New Year Holidays\" or holidays.Russia(years=[2017,2018,2019])[data.date()]==\"Orthodox Christmas Day\":\n",
        "              result.loc[result.DD == data, \"season\"] = \"Новогодние праздники\"\n",
        "        \n",
        "    lower_bound = result.PASS_BK.quantile(q=0.025)\n",
        "    upper_bound = result.PASS_BK.quantile(q=0.975)  \n",
        "    date_ejection = result[(result.PASS_BK < lower_bound) | (result.PASS_BK > upper_bound)].DD.values\n",
        "    if pass_bk>upper_bound:\n",
        "      if data.date() in holidays.Russia(years=[2017,2018,2019]).keys():\n",
        "          if  holidays.Russia(years=[2017,2018,2019])[data.date()]!= \"New Year Holidays\" or holidays.Russia(years=[2017,2018,2019])[data.date()]!=\"Orthodox Christmas Day\":\n",
        "            result.loc[result.DD == data, \"season\"] = holidays.Russia(years=[2017,2018,2019])[data.date()]\n",
        "\n",
        "  return result[[\"DD\",\"PASS_BK\",\"season\"]]\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "b8UspUx8--MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# выгрузка за все время по конкретному классу и номеру рейса\n",
        "flight_num = 1125\n",
        "booking_class = 'J'\n",
        "class_df_season = get_data_to_season('/content/CLASS_012018.csv', flight_num, booking_class)\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_022018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_032018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_042018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_052018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_062018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_072018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_082018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_092018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_102018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_112018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_122018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_012019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_022019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_032019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_042019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_052019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_062019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_072019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_082019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_092019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_102019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_112019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_122019.csv', flight_num, booking_class))\n",
        "res= check_season(class_df_season)"
      ],
      "metadata": {
        "id": "UqZmUFgL_wwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Сезонность спроса (с учетом динамики бронирования)"
      ],
      "metadata": {
        "id": "x9HxQ-vk_543"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# для сезонности динамики бронирования\n",
        "def get_data_to_seasonv2(path,flt_num,class_code):\n",
        "  class_df = pd.read_csv(path, delimiter=';')\n",
        "  class_df = class_df.loc[(class_df['FLT_NUM']==flt_num) &\n",
        "                          (class_df['SEG_CLASS_CODE']==class_code) & (class_df.DTD!=-1) & (~((class_df.FCLCLD==1) & (class_df.DD==class_df.SDAT_S)))] \n",
        "  class_df.DD = class_df.DD.apply(lambda x: datetime.strptime(x, '%d.%m.%Y').date())\n",
        "  class_df.SDAT_S = class_df.SDAT_S.apply(lambda x: datetime.strptime(x, '%d.%m.%Y').date())\n",
        "  return class_df"
      ],
      "metadata": {
        "id": "D_4u-cRC_0gW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_season_booking_dynamics(df):\n",
        "  if df is None:\n",
        "    return None\n",
        "  start_date = df.SDAT_S.min()\n",
        "  end_date = df.SDAT_S.max()\n",
        "  sum=0\n",
        "  try:\n",
        "    res = pd.date_range(\n",
        "        min(start_date, end_date),\n",
        "        max(start_date, end_date)\n",
        "    ).strftime('%Y-%m-%d')\n",
        "  except ValueError:\n",
        "    return None\n",
        "  df_data = pd.DataFrame(columns=[\"SDAT_S\"],data=res)\n",
        "  df_data[\"SDAT_S\"] = df_data.SDAT_S.astype(\"datetime64\")\n",
        "  df_data[\"delta\"] = 0\n",
        "  for dd_i in df.DD.unique():\n",
        "    data_dd_i = get_absolute_booking_dynamics(df[df.DD==dd_i])\n",
        "    if data_dd_i is None:\n",
        "      continue\n",
        "    data_dd_i.SDAT_S = data_dd_i.SDAT_S.astype(\"datetime64\")\n",
        "    df_data = df_data.merge(data_dd_i,on=\"SDAT_S\",how=\"left\").replace(np.nan,0)\n",
        "    \n",
        "    df_data[\"delta\"] = df_data[\"delta_x\"] + df_data[\"delta_y\"]\n",
        "    \n",
        "    df_data = df_data.drop(columns=[\"delta_x\",\"delta_y\"])\n",
        "    \n",
        "  df_data[\"SDAT_S\"] = df_data.SDAT_S.astype(\"datetime64\")\n",
        "\n",
        "  df_to_save = df_data.copy()\n",
        "  df_data = df_data.set_index(\"SDAT_S\")\n",
        "  decomposition = seasonal_decompose(df_data['delta'],model=\"additive\")\n",
        "\n",
        "  df_to_save[\"month\"] = df_to_save[\"SDAT_S\"].apply(lambda x: x.month)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  df_to_save = df_to_save.reset_index(drop=True)\n",
        "  #сделать пока основные сезоны (летний, весенний,зимний и осенний)\n",
        "  df_to_save[\"season\"] = df_to_save.month.apply(lambda x: \"весна\" if (x>=3 and x<=5) else (\"лето\" if (x>=6 and x<=8) else (\"осень\" if (x>=9 and x<=11) else \"зима\")))\n",
        "\n",
        "  result = pd.DataFrame(columns=[\"delta\"], data = decomposition.trend.values)\n",
        "  result[\"delta\"] = result[\"delta\"].replace(np.nan,0)\n",
        "  result[\"SDAT_S\"] = decomposition.trend.index\n",
        " \n",
        "  result[\"season\"] = df_to_save[\"season\"]\n",
        "  \n",
        "\n",
        "  model = \"l1\"  \n",
        "  algo = rpt.Dynp(model=model, min_size=15, jump=5).fit(df_to_save[\"delta\"].values)\n",
        "  my_bkps = algo.predict(n_bkps=10)\n",
        "    \n",
        "  \n",
        "  # прикрутить этот индекс к данным\n",
        "\n",
        "  for i in range(1,len(my_bkps)-1):\n",
        "    if my_bkps[i]!=0:\n",
        "      if result.loc[my_bkps[i]:my_bkps[i+1]].delta.mean() > result.loc[my_bkps[i-1]:my_bkps[i]].delta.mean():\n",
        "        # если среднее по этому промежутку больше, чем в прошлом, то он повышенный\n",
        "        if \"пониженный\" not in result.loc[result.index == my_bkps[i-1], \"season\"].values[0]:\n",
        "          season = result.loc[result.index == my_bkps[i], \"season\"].values[0]\n",
        "          result.loc[my_bkps[i]][\"season\"] = \"повышенный \" + season\n",
        "          j=my_bkps[i]+1\n",
        "          while j<len(result) and j<= my_bkps[i+1]:\n",
        "              season = result.loc[result.index == j, \"season\"].values[0]\n",
        "              result.loc[result.index == j, \"season\"] = \"повышенный \" + season \n",
        "              j+=1\n",
        "\n",
        "      else:\n",
        "        # пониженный или обычный\n",
        "        if \"повышенный\" not in result.loc[result.index == my_bkps[i-1], \"season\"].values[0]:\n",
        "          # делаем пониженный\n",
        "          season = result.loc[result.index == my_bkps[i], \"season\"].values[0]\n",
        "          result.loc[my_bkps[i]][\"season\"] = \"пониженный \" + season\n",
        "          j=my_bkps[i]+1\n",
        "          while  j<len(result) and j<= my_bkps[i+1]:\n",
        "              season = result.loc[result.index == j, \"season\"].values[0]\n",
        "              result.loc[result.index == j, \"season\"] = \"пониженный \" + season \n",
        "              j+=1\n",
        "\n",
        "  # добавить праздники\n",
        "  for delta,data,season in result[[\"delta\",\"SDAT_S\",\"season\"]].values:\n",
        "    if data.date() in holidays.Russia(years=[2017,2018,2019]).keys():\n",
        "          if  holidays.Russia(years=[2017,2018,2019])[data.date()]== \"New Year Holidays\" or holidays.Russia(years=[2017,2018,2019])[data.date()]==\"Orthodox Christmas Day\":\n",
        "              result.loc[result.SDAT_S == data, \"season\"] = \"Новогодние праздники\"\n",
        "        \n",
        "    lower_bound = result.delta.quantile(q=0.025)\n",
        "    upper_bound = result.delta.quantile(q=0.975)  \n",
        "    date_ejection = result[(result.delta < lower_bound) | (result.delta > upper_bound)].SDAT_S.values\n",
        "    if delta>upper_bound:\n",
        "      if data.date() in holidays.Russia(years=[2017,2018,2019]).keys():\n",
        "          if  holidays.Russia(years=[2017,2018,2019])[data.date()]!= \"New Year Holidays\" or holidays.Russia(years=[2017,2018,2019])[data.date()]!=\"Orthodox Christmas Day\":\n",
        "            result.loc[result.SDAT_S == data, \"season\"] = holidays.Russia(years=[2017,2018,2019])[data.date()]\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  return result\n"
      ],
      "metadata": {
        "id": "K5lQHPRbACTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# выгрузка за все время по конкретному классу и номеру рейса\n",
        "flight_num = 1125\n",
        "booking_class = 'J'\n",
        "class_df_season = get_data_to_season('/content/CLASS_012018.csv', flight_num, booking_class)\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_022018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_032018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_042018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_052018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_062018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_072018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_082018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_092018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_102018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_112018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_122018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_012019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_022019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_032019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_042019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_052019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_062019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_072019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_082019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_092019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_102019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_112019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_season('/content/CLASS_122019.csv', flight_num, booking_class))\n",
        "class_df_season"
      ],
      "metadata": {
        "id": "j_QOR8eRAX2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = check_season_booking_dynamics(class_df_season2)"
      ],
      "metadata": {
        "id": "nYle1D0ZAXny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Определение профиля бронирования"
      ],
      "metadata": {
        "id": "XqbaC10mCD68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_to_profile(path,flt_num, class_code):\n",
        "  class_df = pd.read_csv(path, delimiter=';')\n",
        "  class_df = class_df.loc[(class_df['FLT_NUM']==flt_num) &\n",
        "                          (class_df['SEG_CLASS_CODE']==class_code) & (class_df.DTD!=-1) ]\n",
        "  class_df.DD = class_df.DD.apply(lambda x: datetime.strptime(x, '%d.%m.%Y').date())\n",
        "  class_df.SDAT_S = class_df.SDAT_S.apply(lambda x: datetime.strptime(x, '%d.%m.%Y').date())\n",
        "  return class_df"
      ],
      "metadata": {
        "id": "TiyVGONhHTy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_profile(data):\n",
        "  if data is None:\n",
        "    return None\n",
        "  set_delta = set()\n",
        "  \n",
        "  l = {\n",
        "    \"отдых\":[],\n",
        "    \"бизнес/командировки\":[],\n",
        "    \"спонтанное\":[],\n",
        "    \"заранее запланированное\":[]\n",
        "  } \n",
        "  try:\n",
        "    start_date = data.SDAT_S.min()\n",
        "    end_date = data.SDAT_S.max()\n",
        "\n",
        "\n",
        "    res = pd.date_range(\n",
        "        min(start_date, end_date),\n",
        "        max(start_date, end_date)\n",
        "    ).strftime('%Y-%m-%d')\n",
        "\n",
        "    for dd_i in data.DD.unique():\n",
        "      data_i = data[data.DD==dd_i]\n",
        "      \n",
        "      res_booking =  get_booking_dynamics(data_i)\n",
        "      if res_booking is not  None :\n",
        "        day_boom = res_booking[res_booking.delta_freq == res_booking[\"delta_freq\"].values.max()][\"SDAT_S\"].values[0]\n",
        "\n",
        "        delta_active = (dd_i-day_boom).days\n",
        "        if delta_active>60:\n",
        "          l[\"заранее запланированное\"] += [dd_i]\n",
        "\n",
        "        elif delta_active<=60 and delta_active>15:\n",
        "          l[\"отдых\"] +=[dd_i]\n",
        "        elif delta_active>=5 and delta_active<=15:\n",
        "          l[\"бизнес/командировки\"] +=[dd_i]\n",
        "        else:\n",
        "          l[\"спонтанное\"] +=[dd_i]\n",
        "    \n",
        "    result = dict()\n",
        "\n",
        "    if len(l)==0:\n",
        "      return None\n",
        "    df_result = pd.DataFrame(columns=[\"SDAT_S\"],data = res)\n",
        "    for key,values in l.items():\n",
        "      if len(values)==0:\n",
        "        continue\n",
        "      # для каждого спроспа считаем спрос бронирования\n",
        "      df = pd.DataFrame(columns=[\"SDAT_S\"],data=res)\n",
        "      for dd_i in values:\n",
        "        res_data = get_absolute_booking_dynamics(data[data.DD==dd_i])\n",
        "        res_data[\"SDAT_S\"] = res_data[\"SDAT_S\"].astype(\"datetime64\")\n",
        "        df[\"SDAT_S\"] = df.SDAT_S.astype(\"datetime64\")\n",
        "\n",
        "        \n",
        "\n",
        "        df = df.merge(res_data,how=\"outer\",on=\"SDAT_S\",suffixes=(\"\",\"_y\"))\n",
        "        df = df.replace({np.nan:0})\n",
        "        df[\"SDAT_S\"] = df[\"SDAT_S\"].apply(lambda x: datetime.date(x))\n",
        "\n",
        "        if \"delta_y\" in df.columns:\n",
        "          df[\"delta\"] = df[\"delta\"] + df[\"delta_y\"]\n",
        "          df = df.drop(columns=[\"delta_y\"])\n",
        "          df = df.sort_values(by=[\"SDAT_S\"])\n",
        "      result[key] = df \n",
        "      print(\"here\")\n",
        "      df_result[key] =df.delta.values\n",
        "\n",
        "    \n",
        "    \n",
        "\n",
        "    return df_result\n",
        "  except ValueError:\n",
        "    return None"
      ],
      "metadata": {
        "id": "hOP3lWSyHNSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flight_num = 1120\n",
        "booking_class = \"C\"\n",
        "class_df_season = get_data_to_profile('/content/CLASS_012018.csv', flight_num, booking_class)\n",
        "class_df_season = class_df_season.append(get_data_to_profile('/content/CLASS_022018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_profile('/content/CLASS_032018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_profile('/content/CLASS_042018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_profile('/content/CLASS_052018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_profile('/content/CLASS_062018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_profile('/content/CLASS_072018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_profile('/content/CLASS_082018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_profile('/content/CLASS_092018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_profile('/content/CLASS_102018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_profile('/content/CLASS_112018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_profile('/content/CLASS_122018.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_profile('/content/CLASS_012019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_profile('/content/CLASS_022019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_profile('/content/CLASS_032019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_profile('/content/CLASS_042019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_profile('/content/CLASS_052019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_profile('/content/CLASS_062019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_profile('/content/CLASS_072019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_profile('/content/CLASS_082019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_profile('/content/CLASS_092019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_profile('/content/CLASS_102019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_profile('/content/CLASS_112019.csv', flight_num, booking_class))\n",
        "class_df_season = class_df_season.append(get_data_to_profile('/content/CLASS_122019.csv', flight_num, booking_class))\n",
        "res_delta = check_profile(class_df_season)"
      ],
      "metadata": {
        "id": "TYSw7dmIHTG6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
